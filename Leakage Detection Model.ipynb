{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d608a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03_leakage_detection.ipynb\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "data_dir = Path('/mnt/data')\n",
    "out_dir = data_dir / 'outputs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c9268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "payments = pd.read_csv(data_dir / 'payments_system.csv', parse_dates=['timestamp'])\n",
    "refunds = pd.read_csv(data_dir / 'refunds.csv', parse_dates=['refund_timestamp'])\n",
    "refunded = pd.read_csv(out_dir / 'refunded_detailed.csv')   # produced by 02 notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adee3504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify duplicate refunds by transaction_id (multiple refund rows -> duplicates)\n",
    "dup_refund_counts = refunds.groupby('transaction_id').size().reset_index(name='refund_count')\n",
    "duplicate_refunds = dup_refund_counts[dup_refund_counts['refund_count'] > 1].copy()\n",
    "duplicate_refunds.to_csv(out_dir / 'duplicate_refunds_summary.csv', index=False)\n",
    "len(duplicate_refunds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525312d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join refunds to payments to see mismatched customer_ids\n",
    "payments_small = payments[['transaction_id','customer_id']].drop_duplicates()\n",
    "refunds_joined = refunds.merge(payments_small, on='transaction_id', how='left', suffixes=('_refund','_payment'))\n",
    "misallocated = refunds_joined[refunds_joined['customer_id_refund'] != refunds_joined['customer_id_payment']]\n",
    "misallocated.to_csv(out_dir / 'refunds_misallocated.csv', index=False)\n",
    "len(misallocated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc462be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rule: refund_amount > 1.1 * original_amount (if original exists)\n",
    "joined = refunds_joined.merge(payments[['transaction_id','amount']], on='transaction_id', how='left')\n",
    "joined['over_refund_rule'] = joined['refund_amount'] > 1.1 * joined['amount']\n",
    "suspicious_amounts = joined[joined['over_refund_rule'] == True]\n",
    "suspicious_amounts.to_csv(out_dir / 'suspicious_refund_amounts.csv', index=False)\n",
    "len(suspicious_amounts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7912eef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    'duplicate_refund_txns': int(len(duplicate_refunds)),\n",
    "    'misallocated_refunds': int(len(misallocated)),\n",
    "    'suspicious_amount_refunds': int(len(suspicious_amounts))\n",
    "}\n",
    "pd.Series(summary).to_frame('value').to_csv(out_dir / 'leakage_detection_summary.csv')\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244c78fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data_dir = Path('/mnt/data')\n",
    "out_dir = data_dir / 'outputs'\n",
    "\n",
    "refunded = pd.read_csv(out_dir / 'refunded_detailed.csv', parse_dates=['refund_timestamp', 'timestamp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060f90d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create numeric features for anomaly detection\n",
    "refunded['time_to_refund_hours'] = (pd.to_datetime(refunded['refund_timestamp']) - pd.to_datetime(refunded['timestamp'])).dt.total_seconds() / 3600.0\n",
    "refunded['refund_ratio'] = refunded['refund_amount'] / refunded['amount'].replace(0, np.nan)\n",
    "refunded['channel_code'] = refunded['channel'].astype('category').cat.codes\n",
    "\n",
    "features = refunded[['amount','refund_amount','time_to_refund_hours','refund_ratio','channel_code']].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93d8d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(features)\n",
    "\n",
    "model = IsolationForest(n_estimators=200, contamination=0.05, random_state=42)\n",
    "model.fit(X)\n",
    "refunded['anomaly_score'] = model.decision_function(X)\n",
    "refunded['anomaly_flag'] = model.predict(X) == -1\n",
    "\n",
    "refunded.sort_values('anomaly_score').head(20).to_csv(out_dir / 'anomaly_top20.csv', index=False)\n",
    "refunded['anomaly_flag'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4950926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic distribution checks\n",
    "refunded.groupby('anomaly_flag')[['amount','refund_amount']].describe()\n",
    "\n",
    "# Save anomaly-labelled dataset\n",
    "refunded.to_csv(out_dir / 'refunded_with_anomalies.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
